[experiment]
    exp_name = "debug_parsect_dataset"
    exp_dir = "/Users/abhinav/abhi/parsect/parsect/outputs/debug_parsect_dataset"

[dataset]
	name = "train_parsect_dataset"
	class = "ParsectDataset"
	train_filename="/Users/abhinav/abhi/parsect/parsect/data/sectLabel.train.data"
	valid_filename="/Users/abhinav/abhi/parsect/parsect/data/sectLabel.train.data"
	test_filename="/Users/abhinav/abhi/parsect/parsect/data/sectLabel.train.data"
	[dataset.args]
	max_num_words = 1000
	max_instance_length = 100
	word_vocab_store_location = "/Users/abhinav/abhi/parsect/parsect/outputs/debug_parsect_dataset/vocab.json"
	debug = true
	debug_dataset_proportion = 0.1
	word_embedding_type = "random"
	word_embedding_dimension = 300

[model]
    name="simple_classifier"
    class="SimpleClassifier"
    encoding_dim=300
    num_classes=23
    classification_layer_bias=true
    [model.encoder]
        emb_dim = 300
        class="BOW_Encoder"
        name="bag of words encoder"
        dropout_value = 0.5
        aggregation_type="sum"
        [[model.encoder.embedder]]
        name="vanilla embedder"
        class="VanillaEmbedder"
        embed="word_vocab"
        freeze=false

[engine]
    batch_size=32
    save_dir="/Users/abhinav/abhi/parsect/parsect/outputs/debug_parsect_dataset"
    num_epochs=10
    save_every=10
    log_train_metrics_every=10
    tensorboard_logdir="/Users/abhinav/abhi/parsect/parsect/outputs/debug_parsect_dataset"
    device="cpu"
    gradient_norm_clip_value=5.0
    track_for_best="macro_fscore"
    [engine.metric]
        class="PrecisionRecallFMeasure"
    [engine.optimizer]
        class="Adam"
        lr=1e-3
[experiment]
    exp_name = "genericsect-bow-random"
    exp_dir = "genericsect_bow_random_toml"

[dataset]
	class = "GenericSectDataset"
	train_filename="genericSect.train.data"
	valid_filename="genericSect.train.data"
	test_filename="genericSect.train.data"
	[dataset.args]
	max_num_words = 1000
	max_instance_length = 100
	word_vocab_store_location = "genericsect_bow_random_toml/vocab.json"
	debug = true
	debug_dataset_proportion = 0.1
	word_embedding_type = "random"
	word_embedding_dimension = 300

[model]
    class="SimpleClassifier"
    encoding_dim=300
    num_classes=12
    classification_layer_bias=true
    [model.encoder]
        emb_dim = 300
        class="BOW_Encoder"
        dropout_value = 0.5
        aggregation_type="sum"
        [[model.encoder.embedder]]
        class="WordEmbedder"
        embed="word_vocab"
        freeze=false

[engine]
    batch_size=32
    save_dir="genericsect_bow_random_toml/checkpoints"
    num_epochs=1
    save_every=10
    log_train_metrics_every=10
    device="cpu"
    gradient_norm_clip_value=5.0
    [engine.metric]
        class="PrecisionRecallFMeasure"
    [engine.optimizer]
        class="Adam"
        lr=1e-3